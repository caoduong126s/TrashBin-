{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\" Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENVIRONMENT CHECK\n",
      "============================================================\n",
      "\n",
      " PyTorch version: 2.9.1\n",
      " No GPU detected - Training will use CPU\n",
      "  This will be significantly slower!\n",
      "\n",
      " Configuration:\n",
      "  Device: cpu\n",
      "  Batch size: 4\n",
      "  Estimated time: 10-14 hours\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "print(\"=\" * 60)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n PyTorch version: {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  gpu_name = torch.cuda.get_device_name(0)\n",
    "  gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "  print(f\" GPU Available: {gpu_name}\")\n",
    "  print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "  print(f\"  GPU Memory: {gpu_memory:.1f} GB\")\n",
    "  device = 0\n",
    "  batch_size = 16\n",
    "  estimated_time = \"3-4 hours\"\n",
    "else:\n",
    "  print(\" No GPU detected - Training will use CPU\")\n",
    "  print(\"  This will be significantly slower!\")\n",
    "  device = 'cpu'\n",
    "  batch_size = 4\n",
    "  estimated_time = \"10-14 hours\"\n",
    "\n",
    "print(f\"\\n Configuration:\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Estimated time: {estimated_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset path: /Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/data.yaml\n",
      "  Exists: True\n",
      "\n",
      " Dataset configuration found!\n"
     ]
    }
   ],
   "source": [
    "DATA_YAML = Path.home() / \"waste-classification-vn\" / \"yolo-dataset-merged\" / \"data.yaml\"\n",
    "\n",
    "print(f\" Dataset path: {DATA_YAML}\")\n",
    "print(f\"  Exists: {DATA_YAML.exists()}\")\n",
    "\n",
    "if not DATA_YAML.exists():\n",
    "  print(\"\\n ERROR: data.yaml not found!\")\n",
    "  print(\"  Please update DATA_YAML path above\")\n",
    "else:\n",
    "  print(\"\\n Dataset configuration found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET VERIFICATION\n",
      "============================================================\n",
      "\n",
      " Classes: 9\n",
      "\n",
      " Class names:\n",
      "  0: Nh·ª±a\n",
      "  1: Pin\n",
      "  2: V·∫£i\n",
      "  3: Kim lo·∫°i\n",
      "  4: R√°c th·∫£i\n",
      "  5: Th·ªßy tinh\n",
      "  6: Gi·∫•y\n",
      "  7: H·ªôp gi·∫•y\n",
      "  8: H·ªØu c∆°\n",
      "\n",
      " Dataset size:\n",
      "  Train: 6,548 images\n",
      "  Val:  1,637 images\n",
      "  Total: 8,185 images\n",
      "\n",
      " Dataset ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset structure\n",
    "with open(DATA_YAML, encoding='utf-8') as f:\n",
    "  data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n Classes: {data_config['nc']}\")\n",
    "print(f\"\\n Class names:\")\n",
    "for i, name in enumerate(data_config['names']):\n",
    "  print(f\"  {i}: {name}\")\n",
    "\n",
    "# Count files\n",
    "dataset_path = Path(data_config['path'])\n",
    "train_images = dataset_path / 'images' / 'train'\n",
    "val_images = dataset_path / 'images' / 'val'\n",
    "\n",
    "train_count = len(list(train_images.glob('*.*')))\n",
    "val_count = len(list(val_images.glob('*.*')))\n",
    "\n",
    "print(f\"\\n Dataset size:\")\n",
    "print(f\"  Train: {train_count:,} images\")\n",
    "print(f\"  Val:  {val_count:,} images\")\n",
    "print(f\"  Total: {train_count + val_count:,} images\")\n",
    "\n",
    "if train_count == 0 or val_count == 0:\n",
    "  print(\"\\n ERROR: No images found!\")\n",
    "else:\n",
    "  print(\"\\n Dataset ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "üéØ Model: YOLOv8s\n",
      "  Parameters: 11.2M\n",
      "  File size: ~22 MB\n",
      "  Expected mAP@0.5: 85-90%\n",
      "  Inference speed: 50-70 FPS (GPU)\n",
      "\n",
      " Training parameters:\n",
      "  Epochs: 150\n",
      "  Image size: 640x640\n",
      "  Batch size: 4\n",
      "  Early stopping: 25 epochs\n",
      "  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model selection\n",
    "MODEL_SIZE = 'yolov8s.pt' \n",
    "print(f\"\\nüéØ Model: YOLOv8s\")\n",
    "print(f\"  Parameters: 11.2M\")\n",
    "print(f\"  File size: ~22 MB\")\n",
    "print(f\"  Expected mAP@0.5: 85-90%\")\n",
    "print(f\"  Inference speed: 50-70 FPS (GPU)\")\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 150\n",
    "IMG_SIZE = 640\n",
    "PATIENCE = 25\n",
    "\n",
    "print(f\"\\n Training parameters:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Early stopping: {PATIENCE} epochs\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading YOLOv8s pretrained weights...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 25.1MB/s 0.9s0.8s<0.1ss1\n",
      " Model loaded successfully!\n",
      "\n",
      "Model summary:\n",
      "YOLOv8s summary: 129 layers, 11,166,560 parameters, 0 gradients, 28.8 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 11166560, 0, 28.816844800000002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained YOLOv8s\n",
    "print(\" Loading YOLOv8s pretrained weights...\")\n",
    "model = YOLO(MODEL_SIZE)\n",
    "print(\" Model loaded successfully!\")\n",
    "\n",
    "# Display model info\n",
    "print(f\"\\nModel summary:\")\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " STARTING TRAINING\n",
      "======================================================================\n",
      "\n",
      "Estimated time: 10-14 hours\n",
      "You can monitor progress below...\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.4.6 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.252 Python-3.11.14 torch-2.9.1 CPU (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/data.yaml, degrees=15.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=waste_production_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/caoduong22102004gmail.com/waste-classification-vn/notebooks/runs/detect/runs/detect/waste_production_v1, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "          from n  params module                    arguments           \n",
      " 0         -1 1    928 ultralytics.nn.modules.conv.Conv       [3, 32, 3, 2]         \n",
      " 1         -1 1   18560 ultralytics.nn.modules.conv.Conv       [32, 64, 3, 2]        \n",
      " 2         -1 1   29056 ultralytics.nn.modules.block.C2f       [64, 64, 1, True]       \n",
      " 3         -1 1   73984 ultralytics.nn.modules.conv.Conv       [64, 128, 3, 2]        \n",
      " 4         -1 2  197632 ultralytics.nn.modules.block.C2f       [128, 128, 2, True]      \n",
      " 5         -1 1  295424 ultralytics.nn.modules.conv.Conv       [128, 256, 3, 2]       \n",
      " 6         -1 2  788480 ultralytics.nn.modules.block.C2f       [256, 256, 2, True]      \n",
      " 7         -1 1  1180672 ultralytics.nn.modules.conv.Conv       [256, 512, 3, 2]       \n",
      " 8         -1 1  1838080 ultralytics.nn.modules.block.C2f       [512, 512, 1, True]      \n",
      " 9         -1 1  656896 ultralytics.nn.modules.block.SPPF      [512, 512, 5]         \n",
      " 10         -1 1     0 torch.nn.modules.upsampling.Upsample     [None, 2, 'nearest']     \n",
      " 11       [-1, 6] 1     0 ultralytics.nn.modules.conv.Concat      [1]              \n",
      " 12         -1 1  591360 ultralytics.nn.modules.block.C2f       [768, 256, 1]         \n",
      " 13         -1 1     0 torch.nn.modules.upsampling.Upsample     [None, 2, 'nearest']     \n",
      " 14       [-1, 4] 1     0 ultralytics.nn.modules.conv.Concat      [1]              \n",
      " 15         -1 1  148224 ultralytics.nn.modules.block.C2f       [384, 128, 1]         \n",
      " 16         -1 1  147712 ultralytics.nn.modules.conv.Conv       [128, 128, 3, 2]       \n",
      " 17      [-1, 12] 1     0 ultralytics.nn.modules.conv.Concat      [1]              \n",
      " 18         -1 1  493056 ultralytics.nn.modules.block.C2f       [384, 256, 1]         \n",
      " 19         -1 1  590336 ultralytics.nn.modules.conv.Conv       [256, 256, 3, 2]       \n",
      " 20       [-1, 9] 1     0 ultralytics.nn.modules.conv.Concat      [1]              \n",
      " 21         -1 1  1969152 ultralytics.nn.modules.block.C2f       [768, 512, 1]         \n",
      " 22    [15, 18, 21] 1  2119531 ultralytics.nn.modules.head.Detect      [9, [128, 256, 512]]     \n",
      "Model summary: 129 layers, 11,139,083 parameters, 11,139,067 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access (ping: 0.0¬±0.0 ms, read: 104.2¬±49.5 MB/s, size: 20.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/labels/train... 6548 images, 1 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6548/6548 7.5Kit/s 0.9s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access (ping: 0.0¬±0.0 ms, read: 242.9¬±162.4 MB/s, size: 32.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/labels/val... 1637 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1637/1637 8.1Kit/s 0.2s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/caoduong22102004gmail.com/waste-classification-vn/yolo-dataset-merged/labels/val.cache\n",
      "Plotting labels to /Users/caoduong22102004gmail.com/waste-classification-vn/notebooks/runs/detect/runs/detect/waste_production_v1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/caoduong22102004gmail.com/waste-classification-vn/notebooks/runs/detect/runs/detect/waste_production_v1\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "   Epoch  GPU_mem  box_loss  cls_loss  dfl_loss Instances    Size\n",
      "\u001b[K   1/150     0G    1.95   5.041   2.311     12    640: 2% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 26/1637 1.4s/it 38.4s<37:05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m   5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEstimated time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimated_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYou can monitor progress below...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Data\u001b[39;49;00m\n\u001b[32m   10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDATA_YAML\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   11\u001b[39m \n\u001b[32m   12\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training duration\u001b[39;49;00m\n\u001b[32m   13\u001b[39m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   14\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   15\u001b[39m \n\u001b[32m   16\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input\u001b[39;49;00m\n\u001b[32m   17\u001b[39m \u001b[43m  \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   18\u001b[39m \u001b[43m  \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   19\u001b[39m \n\u001b[32m   20\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Hardware\u001b[39;49;00m\n\u001b[32m   21\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   22\u001b[39m \u001b[43m  \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   23\u001b[39m \n\u001b[32m   24\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Project organization\u001b[39;49;00m\n\u001b[32m   25\u001b[39m \u001b[43m  \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mruns/detect\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   26\u001b[39m \u001b[43m  \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwaste_production_v1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   27\u001b[39m \u001b[43m  \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   28\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   29\u001b[39m \n\u001b[32m   30\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Checkpointing\u001b[39;49;00m\n\u001b[32m   31\u001b[39m \u001b[43m  \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   32\u001b[39m \u001b[43m  \u001b[49m\u001b[43msave_period\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   33\u001b[39m \n\u001b[32m   34\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation\u001b[39;49;00m\n\u001b[32m   35\u001b[39m \u001b[43m  \u001b[49m\u001b[43mval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   36\u001b[39m \u001b[43m  \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   37\u001b[39m \n\u001b[32m   38\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# === DATA AUGMENTATION ===\u001b[39;49;00m\n\u001b[32m   39\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Color augmentation\u001b[39;49;00m\n\u001b[32m   40\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhsv_h\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.015\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   41\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhsv_s\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   42\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   43\u001b[39m \n\u001b[32m   44\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Geometric augmentation\u001b[39;49;00m\n\u001b[32m   45\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   46\u001b[39m \u001b[43m  \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   47\u001b[39m \u001b[43m  \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   48\u001b[39m \u001b[43m  \u001b[49m\u001b[43mshear\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   49\u001b[39m \u001b[43m  \u001b[49m\u001b[43mperspective\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   50\u001b[39m \n\u001b[32m   51\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Flip augmentation\u001b[39;49;00m\n\u001b[32m   52\u001b[39m \u001b[43m  \u001b[49m\u001b[43mflipud\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   53\u001b[39m \u001b[43m  \u001b[49m\u001b[43mfliplr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   54\u001b[39m \n\u001b[32m   55\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Advanced augmentation\u001b[39;49;00m\n\u001b[32m   56\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   57\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmixup\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   58\u001b[39m \u001b[43m  \u001b[49m\u001b[43mcopy_paste\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   59\u001b[39m \n\u001b[32m   60\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# === HYPERPARAMETERS ===\u001b[39;49;00m\n\u001b[32m   61\u001b[39m \u001b[43m  \u001b[49m\u001b[43mlr0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   62\u001b[39m \u001b[43m  \u001b[49m\u001b[43mlrf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   63\u001b[39m \u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSGD\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   64\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.937\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   65\u001b[39m \u001b[43m  \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   66\u001b[39m \u001b[43m  \u001b[49m\u001b[43mcos_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   67\u001b[39m \u001b[43m  \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   68\u001b[39m \u001b[43m  \u001b[49m\u001b[43mwarmup_momentum\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   69\u001b[39m \u001b[43m  \u001b[49m\u001b[43mwarmup_bias_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   70\u001b[39m \n\u001b[32m   71\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# === LOSS WEIGHTS ===\u001b[39;49;00m\n\u001b[32m   72\u001b[39m \u001b[43m  \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   73\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   74\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdfl\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   75\u001b[39m \n\u001b[32m   76\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# === OPTIMIZATIONS ===\u001b[39;49;00m\n\u001b[32m   77\u001b[39m \u001b[43m  \u001b[49m\u001b[43mclose_mosaic\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   78\u001b[39m \u001b[43m  \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   79\u001b[39m \u001b[43m  \u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   80\u001b[39m \n\u001b[32m   81\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# === SETTINGS ===\u001b[39;49;00m\n\u001b[32m   82\u001b[39m \u001b[43m  \u001b[49m\u001b[43miou\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   83\u001b[39m \u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   84\u001b[39m \u001b[43m  \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   85\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m   87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m   88\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m TRAINING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/ultralytics/engine/model.py:774\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m  771\u001b[39m   \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m  772\u001b[39m   \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  775\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m  776\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:242\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  239\u001b[39m     ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m  241\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:435\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  433\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.scale(\u001b[38;5;28mself\u001b[39m.loss).backward()\n\u001b[32m  434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  436\u001b[39m   last_opt_step = ni\n\u001b[32m  438\u001b[39m   \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:686\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  684\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer) \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m  685\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), max_norm=\u001b[32m10.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  687\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m  688\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:385\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m  363\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[32m  364\u001b[39m \n\u001b[32m  365\u001b[39m \u001b[33;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[32m  (...)\u001b[39m\u001b[32m  382\u001b[39m \u001b[33;03m  Closure use is not currently supported.\u001b[39;00m\n\u001b[32m  383\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enabled:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m  388\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m  389\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  390\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m  131\u001b[39m opt = opt_ref()\n\u001b[32m  132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m  512\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m  513\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m  514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  515\u001b[39m       )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m  520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   80\u001b[39m   torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   81\u001b[39m   torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m   ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   84\u001b[39m   torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/sgd.py:127\u001b[39m, in \u001b[36mSGD.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m  121\u001b[39m momentum_buffer_list: \u001b[38;5;28mlist\u001b[39m[Optional[Tensor]] = []\n\u001b[32m  123\u001b[39m has_sparse_grad = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m  124\u001b[39m   group, params, grads, momentum_buffer_list\n\u001b[32m  125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  128\u001b[39m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  129\u001b[39m \u001b[43m  \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  130\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  131\u001b[39m \u001b[43m  \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  132\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  133\u001b[39m \u001b[43m  \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  134\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdampening\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  135\u001b[39m \u001b[43m  \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnesterov\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  136\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  137\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  138\u001b[39m \u001b[43m  \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  139\u001b[39m \u001b[43m  \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  140\u001b[39m \u001b[43m  \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  141\u001b[39m \u001b[43m  \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[33m\"\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[32m0\u001b[39m:\n\u001b[32m  145\u001b[39m   \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[32m  146\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/sgd.py:304\u001b[39m, in \u001b[36msgd\u001b[39m\u001b[34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[39m\n\u001b[32m  301\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m  302\u001b[39m   func = _single_tensor_sgd\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  305\u001b[39m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  306\u001b[39m \u001b[43m  \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  307\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  308\u001b[39m \u001b[43m  \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  309\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  310\u001b[39m \u001b[43m  \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  311\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  312\u001b[39m \u001b[43m  \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  313\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  314\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  315\u001b[39m \u001b[43m  \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  316\u001b[39m \u001b[43m  \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  317\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/waste-classification-vn/venv/lib/python3.11/site-packages/torch/optim/sgd.py:364\u001b[39m, in \u001b[36m_single_tensor_sgd\u001b[39m\u001b[34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[39m\n\u001b[32m  361\u001b[39m   buf.mul_(momentum).add_(grad, alpha=\u001b[32m1\u001b[39m - dampening)\n\u001b[32m  363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nesterov:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m   grad = \u001b[43mgrad\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  365\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m  366\u001b[39m   grad = buf\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# PRODUCTION-OPTIMIZED TRAINING\n",
    "print(\"=\" * 70)\n",
    "print(\" STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEstimated time: {estimated_time}\")\n",
    "print(\"You can monitor progress below...\\n\")\n",
    "\n",
    "results = model.train(\n",
    "  # Data\n",
    "  data=str(DATA_YAML),\n",
    "  \n",
    "  # Training duration\n",
    "  epochs=EPOCHS,\n",
    "  patience=PATIENCE,\n",
    "  \n",
    "  # Input\n",
    "  imgsz=IMG_SIZE,\n",
    "  batch=batch_size,\n",
    "  \n",
    "  # Hardware\n",
    "  device=device,\n",
    "  workers=8,\n",
    "  \n",
    "  # Project organization\n",
    "  project='runs/detect',\n",
    "  name='waste_production_v1',\n",
    "  exist_ok=False,\n",
    "  pretrained=True,\n",
    "  \n",
    "  # Checkpointing\n",
    "  save=True,\n",
    "  save_period=10,\n",
    "  \n",
    "  # Validation\n",
    "  val=True,\n",
    "  plots=True,\n",
    "  \n",
    "  # === DATA AUGMENTATION ===\n",
    "  # Color augmentation\n",
    "  hsv_h=0.015,\n",
    "  hsv_s=0.7,\n",
    "  hsv_v=0.4,\n",
    "  \n",
    "  # Geometric augmentation\n",
    "  degrees=15.0,\n",
    "  translate=0.1,\n",
    "  scale=0.5,\n",
    "  shear=0.0,\n",
    "  perspective=0.0,\n",
    "  \n",
    "  # Flip augmentation\n",
    "  flipud=0.0,\n",
    "  fliplr=0.5,\n",
    "  \n",
    "  # Advanced augmentation\n",
    "  mosaic=1.0,\n",
    "  mixup=0.0,\n",
    "  copy_paste=0.0,\n",
    "  \n",
    "  # === HYPERPARAMETERS ===\n",
    "  lr0=0.01,\n",
    "  lrf=0.01,\n",
    "  optimizer='SGD',\n",
    "  momentum=0.937,\n",
    "  weight_decay=0.0005,\n",
    "  cos_lr=True,\n",
    "  warmup_epochs=3.0,\n",
    "  warmup_momentum=0.8,\n",
    "  warmup_bias_lr=0.1,\n",
    "  \n",
    "  # === LOSS WEIGHTS ===\n",
    "  box=7.5,\n",
    "  cls=0.5,\n",
    "  dfl=1.5,\n",
    "  \n",
    "  # === OPTIMIZATIONS ===\n",
    "  close_mosaic=10,\n",
    "  amp=True,\n",
    "  fraction=1.0,\n",
    "  \n",
    "  # === SETTINGS ===\n",
    "  iou=0.7,\n",
    "  verbose=True,\n",
    "  seed=42,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "metrics = model.val()\n",
    "\n",
    "# Overall performance\n",
    "print(f\"\\n Overall Performance:\")\n",
    "print(f\"  mAP@0.5:   {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
    "print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
    "print(f\"  Precision:  {metrics.box.mp:.4f} ({metrics.box.mp*100:.2f}%)\")\n",
    "print(f\"  Recall:    {metrics.box.mr:.4f} ({metrics.box.mr*100:.2f}%)\")\n",
    "\n",
    "# Per-class performance\n",
    "print(f\"\\n Per-Class Performance (mAP@0.5):\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "\n",
    "for i, (name, ap) in enumerate(zip(metrics.names.values(), metrics.box.maps)):\n",
    " status = \"\" if ap > 0.80 else \"\" if ap > 0.70 else \"\"\n",
    "  print(f\"  {status} {i}: {name:15s} ‚Üí {ap:.4f} ({ap*100:.2f}%)\")\n",
    "\n",
    "# Performance assessment\n",
    "print(f\"\\n Performance Assessment:\")\n",
    "if metrics.box.map50 >= 0.85:\n",
    "  print(f\"  EXCELLENT! (‚â•85% mAP)\")\n",
    "  print(f\"  ‚Üí Production-ready\")\n",
    "elif metrics.box.map50 >= 0.75:\n",
    "  print(f\"  GOOD! (75-85% mAP)\")\n",
    "  print(f\"  ‚Üí Acceptable for production\")\n",
    "else:\n",
    "  print(f\"   NEEDS IMPROVEMENT (<75% mAP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "save_dir = Path(results.save_dir)\n",
    "\n",
    "print(\" Training Visualizations:\\n\")\n",
    "\n",
    "# Results plot\n",
    "results_plot = save_dir / 'results.png'\n",
    "if results_plot.exists():\n",
    "  print(\"Training & Validation Metrics:\")\n",
    "  display(Image(filename=str(results_plot)))\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix = save_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix.exists():\n",
    "  print(\"\\nConfusion Matrix:\")\n",
    "  display(Image(filename=str(confusion_matrix)))\n",
    "\n",
    "# Predictions\n",
    "val_batch = save_dir / 'val_batch0_pred.jpg'\n",
    "if val_batch.exists():\n",
    "  print(\"\\nSample Predictions:\")\n",
    "  display(Image(filename=str(val_batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model file paths\n",
    "best_model = save_dir / 'weights' / 'best.pt'\n",
    "last_model = save_dir / 'weights' / 'last.pt'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" MODEL FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n Save directory: {save_dir}\")\n",
    "print(f\"\\n Best model: {best_model}\")\n",
    "print(f\"  Size: {best_model.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "print(f\"\\n Last model: {last_model}\")\n",
    "print(f\"  Size: {last_model.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "print(f\"\\n Training plots: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test Model on Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for inference\n",
    "best_model_loaded = YOLO(str(best_model))\n",
    "\n",
    "print(\"üß™ Testing model on sample validation image...\\n\")\n",
    "\n",
    "# Get a random validation image\n",
    "val_images_list = list(val_images.glob('*.jpg'))\n",
    "if val_images_list:\n",
    "  test_image = val_images_list[0]\n",
    "  \n",
    "  # Run inference\n",
    "  results_test = best_model_loaded(str(test_image))\n",
    "  \n",
    "  # Display results\n",
    "  for r in results_test:\n",
    "    print(f\"Detections: {len(r.boxes)} objects found\")\n",
    "    \n",
    "    # Show image with predictions\n",
    "    im_array = r.plot()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(im_array[..., ::-1]) # BGR to RGB\n",
    "    plt.axis('off')\n",
    "    plt.title('Sample Detection Result')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detections\n",
    "    if len(r.boxes) > 0:\n",
    "      print(\"\\nDetected objects:\")\n",
    "      for box in r.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        name = r.names[cls]\n",
    "        print(f\"  {name}: {conf:.2%}\")\n",
    "else:\n",
    "  print(\"No validation images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "print(\"=\" * 70)\n",
    "print(\" EXPORTING MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Export to ONNX (recommended for production)\n",
    "print(\"\\n Exporting to ONNX format...\")\n",
    "onnx_path = best_model_loaded.export(format='onnx')\n",
    "print(f\"  ONNX model: {onnx_path}\")\n",
    "\n",
    "# Export to TensorFlow Lite (for mobile)\n",
    "print(\"\\n Exporting to TFLite format (for mobile)...\")\n",
    "try:\n",
    "  tflite_path = best_model_loaded.export(format='tflite')\n",
    "  print(f\"  TFLite model: {tflite_path}\")\n",
    "except Exception as e:\n",
    "  print(f\"   TFLite export failed: {e}\")\n",
    "\n",
    "print(\"\\n Export complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" TRAINING PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n Final Results:\")\n",
    "print(f\"  Model: YOLOv8s\")\n",
    "print(f\"  mAP@0.5: {metrics.box.map50*100:.2f}%\")\n",
    "print(f\"  Precision: {metrics.box.mp*100:.2f}%\")\n",
    "print(f\"  Recall: {metrics.box.mr*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n Model Files:\")\n",
    "print(f\"  PyTorch: {best_model}\")\n",
    "print(f\"  ONNX: {onnx_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (waste-clean)",
   "language": "python",
   "name": "waste-venv-clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
